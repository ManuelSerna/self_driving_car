# -*- coding: utf-8 -*-
"""cnn.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ZnfedoMrY-zpOsTj0OkSLjDXynbQcaY3
"""

#*************************************************************************
# Convolutional Neural Network tutorial
# Note: file created on Colaboratory. Multiple cells display graphs, if you run this code on the shell it will likely come out weird.
#*************************************************************************
import numpy as np
import matplotlib.pyplot as plt
import keras
from keras.datasets import mnist
from keras.models import Sequential
from keras.layers import Dense
from keras.optimizers import Adam
from keras.utils.np_utils import to_categorical
from keras.layers import Flatten # This function will be used to flatten the data for the neural network
'''
The two imports below create the convolutional and pooling layers respectively.
The Lenet contains two of each of these layers.
'''
from keras.layers.convolutional import Conv2D
from keras.layers.convolutional import MaxPooling2D
from keras.layers import Dropout # add dropout to reduce overfitting of data
'''
API, allows us to define a model, much like Sequential, allows us 
to instantiate layers from pre-trained models. 
Effectively allowing us to reuse sections of previously trained models.
'''
from keras.models import Model
import random

np.random.seed(0)

(X_train, y_train), (X_test, y_test)= mnist.load_data()
 
print(X_train.shape)
print(X_test.shape)

assert(X_train.shape[0] == y_train.shape[0]), "The number of images is not equal to the number of labels."
assert(X_train.shape[1:] == (28,28)), "The dimensions of the images are not 28 x 28."
assert(X_test.shape[0] == y_test.shape[0]), "The number of images is not equal to the number of labels."
assert(X_test.shape[1:] == (28,28)), "The dimensions of the images are not 28 x 28."

num_of_samples=[]
 
cols = 5
num_classes = 10
 
fig, axs = plt.subplots(nrows=num_classes, ncols=cols, figsize=(5,10))
fig.tight_layout()
 
for i in range(cols):
    for j in range(num_classes):
        x_selected = X_train[y_train == j]
        axs[j][i].imshow(x_selected[random.randint(0,(len(x_selected) - 1)), :, :], cmap=plt.get_cmap('gray'))
        axs[j][i].axis("off")
        if i == 2:
            axs[j][i].set_title(str(j))
            num_of_samples.append(len(x_selected))

print(num_of_samples)
plt.figure(figsize=(12, 4))
plt.bar(range(0, num_classes), num_of_samples)
plt.title("Distribution of the train dataset")
plt.xlabel("Class number")
plt.ylabel("Number of images")
plt.show()

# First step to preparing data, add a depth of 1 to account for the greyscale.
X_train = X_train.reshape(60000, 28, 28, 1) # Keep as a 28x28 image with a depth of 1.
X_test = X_test.reshape(10000, 28, 28, 1)

y_train = to_categorical(y_train, 10)
y_test = to_categorical(y_test, 10)
 
X_train = X_train/255
X_test = X_test/255

'''
Create the convolutional neural network, we can pick from many convolutional architectures
Here, A Lenet-based model will be made.
'''
#================================================================
# Define the leNet model function
'''
Applying dropout: randomly sets some input units to zero at each update during training, which helps with overfitting.
Different nodes set to zero at different nodes, the network is forced to learn with a unique node arrangement each time.
As a result, it is more versatile after training.
'''
#================================================================
def leNet_model():
    model = Sequential() # define model using sequential class
    # Start by adding a layer to the model, in this step, insert a convolutional layer.
    '''
    Arg 1: num filters, the more you have, the more computing power needed 
    Arg 2: filter size (of 5x5 for the 28x28 images)
    Arg 3: input will be fed an image that is 28x28 with one channel (greyscale, hence a depth of 1)
    Arg 4: activation function, use the ReLU function
    
    The image will be reduced to 30 feature maps, each 24x24.
    
    Padding works to preserve the spatial dimensionality of the image.
        * Same padding: making the output matrix size the same as the input.
            - Allows to extract low-level features.
    '''
    model.add(Conv2D(30, (5,5), input_shape=(28,28,1), activation='relu')) # use 30 filters of size 5x5
    
    # Add pooling layer
    model.add(MaxPooling2D(pool_size=(2, 2))) # only 1 arg: size of pooling element

    # Add another convolutional layer. Use smaller filter to extract features.
    model.add(Conv2D(15, (3,3), activation='relu')) # have 4,065 parameters, use 15 filters of size 3x3
    
    # Add another pooling layer
    model.add(MaxPooling2D(pool_size=(2, 2))) # produce a 5x5 image with a depth of 50
    
    # Take convoluted data and feed into the fully connected layer
    model.add(Flatten())
    model.add(Dense(500, activation='relu'))
    
    '''
    Use a single dropout layer.
    Although more can be used, and in different places, they are used in between layers that have a high number of parameters, these are more likely to overfit.
    
    Arg 1: fraction rate, the amount of input nodes that the dropout layer drops during each update.
    0 = no nodes dropped.
    1 = all nodes dropped.
    RECOMMENDED = 0.5
    '''
    model.add(Dropout(0.5))
    
    # Define output layer
    model.add(Dense(num_classes, activation='softmax'))
    model.compile(Adam(lr=0.01), loss='categorical_crossentropy', metrics=['accuracy'])
    
    return model
#----------------------------------------------------------------

model = leNet_model()
print(model.summary())

history = model.fit(X_train, y_train, epochs=10, validation_split=0.1, batch_size=400, verbose=1, shuffle=1)

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.legend(['loss', 'val_loss'])
plt.title('Loss')
plt.xlabel('epoch')

plt.plot(history.history['acc'])
plt.plot(history.history['val_acc'])
plt.legend(['acc', 'val_acc'])
plt.title('Accuracy')
plt.xlabel('epoch')

import requests
from PIL import Image

url = 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcST8KzXHtkSHcxzdpnllMhAj0upLEwnNFdtY6j4YUPcmaf4Ty3u'
response = requests.get(url, stream=True)
img = Image.open(response.raw)
plt.imshow(img, cmap=plt.get_cmap('gray'))

import cv2
 
img = np.asarray(img)
img = cv2.resize(img, (28, 28))
img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
img = cv2.bitwise_not(img)
plt.imshow(img, cmap=plt.get_cmap('gray'))

img = img/255
img = img.reshape(1, 28, 28, 1)

# Accuracy is improved over a neural network, from 93% to close to 99% on the same data set
prediction = model.predict_classes(img)
print("predicted digit:", str(prediction))

score = model.evaluate(X_test, y_test, verbose=0)
print(type(score))
print('Test score:', score[0])
print('Test accuracy:', score[1])

# Get visual on layers
# get inputs that were passed into the first layer, get what comes out of the first and third layer
layer1 = Model(inputs=model.layers[0].input, outputs=model.layers[0].output)
layer2 = Model(inputs=model.layers[0].input, outputs=model.layers[2].output)
# Model API will complete all the necessary calculations from the inputs to the outputs

visual_layer1, visual_layer2 = layer1.predict(img), layer2.predict(img)# feed image of number into layer 1

print(visual_layer1.shape)
print(visual_layer2.shape)

plt.figure(figsize=(10, 6))
for i in range(30):
    plt.subplot(6, 5, i+1)
    plt.imshow(visual_layer1[0, :, :, i], cmap=plt.get_cmap('jet'))
    plt.axis('off')

plt.figure(figsize=(10, 6))
for i in range(15):
    plt.subplot(3, 5, i+1)
    plt.imshow(visual_layer2[0, :, :, i], cmap=plt.get_cmap('jet'))
    plt.axis('off')
